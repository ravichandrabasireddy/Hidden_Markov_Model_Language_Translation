{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9799afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "hmm_model_file=open(\"hmmmodel.txt\")\n",
    "hmm_output_file=open(\"hmmoutput.txt\", mode='w')\n",
    "hmm_model=json.load(hmm_model_file)\n",
    "tag_count,emission_count,transition_count,most_probable_count=hmm_model['tag_count'],hmm_model['emission_count'],hmm_model['transition_count'],hmm_model['most_probable_count'][0:5]\n",
    "\n",
    "def get_lines_dev_data(file_path):\n",
    "    dev_data_lines=[]\n",
    "    with open(file_path) as hmm_dev_file:\n",
    "        for lines in hmm_dev_file.readlines():\n",
    "            dev_data_lines.append(lines.rstrip())\n",
    "    return dev_data_lines\n",
    "\n",
    "test_dev_data_file=\"hmm-training-data/it_isdt_dev_raw.txt\"\n",
    "test_dev_lines=get_lines_dev_data(test_dev_data_file)\n",
    "\n",
    "start_tag='<s>'\n",
    "end_tag='<e>'\n",
    "\n",
    "for line in test_dev_lines:\n",
    "    word_exists_flag,tags=0,[]\n",
    "    hmm_probabilities,hmm_backpointers=[{}],[{}]\n",
    "    words_to_tagged=line.split(\" \")\n",
    "    word_exists_flag,word_index=0,0\n",
    "    word_to_tag=words_to_tagged[word_index]\n",
    "    if word_to_tag in emission_count.keys():\n",
    "        word_exists_flag=1\n",
    "        word_tags=emission_count[word_to_tag].keys()\n",
    "    else:\n",
    "        word_tags=most_probable_count\n",
    "    for word_tag in word_tags:\n",
    "        if word_exists_flag:\n",
    "            hmm_probabilities[word_index][word_tag]=transition_count[start_tag][word_tag]*emission_count[word_to_tag][word_tag]\n",
    "        else:\n",
    "            hmm_probabilities[word_index][word_tag]=transition_count[start_tag][word_tag]\n",
    "        hmm_backpointers[word_index][word_tag]=start_tag\n",
    "    for word_index in range(1,len(words_to_tagged)):\n",
    "        word_to_tag=words_to_tagged[word_index]\n",
    "        word_exists_flag=0\n",
    "        hmm_probabilities.append({})\n",
    "        hmm_backpointers.append({})\n",
    "        if word_to_tag in emission_count.keys():\n",
    "            word_exists_flag=1\n",
    "            word_tags=emission_count[word_to_tag].keys()\n",
    "        else:\n",
    "            word_tags=most_probable_count\n",
    "        for word_tag in word_tags:\n",
    "            if word_tag==start_tag or word_tag==end_tag:\n",
    "                continue\n",
    "            max_probability,max_state=-1,''\n",
    "            for tag_new in hmm_probabilities[word_index-1]:\n",
    "                if word_exists_flag:\n",
    "                    current_probability=transition_count[tag_new][word_tag] * emission_count[word_to_tag][word_tag] * hmm_probabilities[word_index-1][tag_new]\n",
    "                else:\n",
    "                    current_probability=transition_count[tag_new][word_tag] * hmm_probabilities[word_index-1][tag_new]\n",
    "                if max_probability<current_probability:\n",
    "                    max_probability=current_probability\n",
    "                    max_state=tag_new  \n",
    "            hmm_backpointers[word_index][word_tag]=max_state\n",
    "            hmm_probabilities[word_index][word_tag]=max_probability\n",
    "    \n",
    "    max_probability,max_state=-1,''\n",
    "    hmm_probabilities.append({})\n",
    "    hmm_backpointers.append({})\n",
    "    for word_tag in hmm_probabilities[len(words_to_tagged)-1]:\n",
    "        current_probability=transition_count[word_tag][end_tag]*hmm_probabilities[len(words_to_tagged)-1][word_tag]\n",
    "        if max_probability<current_probability:\n",
    "            max_probability=current_probability\n",
    "            max_state=word_tag\n",
    "    hmm_backpointers[len(words_to_tagged)][end_tag]=max_state\n",
    "    hmm_probabilities[len(words_to_tagged)][end_tag]=max_probability\n",
    "    \n",
    "    length_of_hmm_probabilities = len(hmm_probabilities)\n",
    "    start = end_tag\n",
    "    word=words_to_tagged[length_of_hmm_probabilities-2]\n",
    "    tag=hmm_backpointers[length_of_hmm_probabilities-1][start]\n",
    "    taggings =word + \"/\" +tag\n",
    "    start = hmm_backpointers[length_of_hmm_probabilities-1][start]\n",
    "    hmm_probabilities.pop()\n",
    "    length_of_hmm_probabilities -= 1\n",
    "\n",
    "    while len(hmm_probabilities)-1:\n",
    "        word=words_to_tagged[length_of_hmm_probabilities-2]\n",
    "        tag=hmm_backpointers[length_of_hmm_probabilities-1][start]\n",
    "        taggings =word + \"/\" +tag+\" \"+taggings\n",
    "        start = hmm_backpointers[length_of_hmm_probabilities-1][start]\n",
    "        length_of_hmm_probabilities -= 1\n",
    "        hmm_probabilities.pop()\n",
    "\n",
    "    hmm_output_file.write(taggings)\n",
    "    hmm_output_file.write('\\n')\n",
    "hmm_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907dd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
