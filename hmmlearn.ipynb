{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ecc7c4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0f/nsn695d16y19hjmm0y50nm1r0000gn/T/ipykernel_9060/209660621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mhmm_training_data_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlines_in_training_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_lines_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_training_data_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_in_training_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlines_in_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_words_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines_in_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0f/nsn695d16y19hjmm0y50nm1r0000gn/T/ipykernel_9060/209660621.py\u001b[0m in \u001b[0;36mget_lines_training_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_lines_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtraining_data_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhmm_training_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhmm_training_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtraining_data_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "def get_lines_training_data(file_path):\n",
    "    training_data_lines=[]\n",
    "    with open(file_path) as hmm_training_file:\n",
    "        for lines in hmm_training_file.readlines():\n",
    "            training_data_lines.append(lines.rstrip())\n",
    "    return training_data_lines\n",
    "\n",
    "def get_words_training_data(line):\n",
    "    start_tag=\"/<s>\"\n",
    "    end_tag=\"/<e>\"\n",
    "    line=start_tag+\" \"+line+\" \"+end_tag\n",
    "    return line.split(\" \")\n",
    "\n",
    "def check_new_tag(individual_word_tags,word):\n",
    "    if tag in individual_word_tags.keys():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "hmm_training_data_file_path=sys.argv[1]\n",
    "lines_in_training_data=get_lines_training_data(hmm_training_data_file_path)\n",
    "for index in range(len(lines_in_training_data)):\n",
    "    lines_in_training_data[index]=get_words_training_data(lines_in_training_data[index])\n",
    "unique_tags=set()\n",
    "individual_word_tags={}\n",
    "tag_count={}\n",
    "emission_count={}\n",
    "emission={}\n",
    "transition_count={}\n",
    "start_tag='<s>'\n",
    "end_tag='<e>'\n",
    "for line in lines_in_training_data:\n",
    "    pre_tag=start_tag\n",
    "    transition_count.setdefault(pre_tag,{})\n",
    "    transition_count.setdefault(end_tag,{})\n",
    "    for word_tag in line:\n",
    "        word_tag_split=word_tag.rpartition(\"/\")\n",
    "        word,tag=word_tag_split[0],word_tag_split[2]\n",
    "        unique_tags.add(tag)\n",
    "        tag_count[tag]=tag_count.get(tag,0)+1\n",
    "        if word==\"\":\n",
    "            continue\n",
    "        if tag!=start_tag and tag!=end_tag:\n",
    "            if individual_word_tags.get(tag) is not None:\n",
    "                individual_word_tags[tag].add(word)            \n",
    "            else:\n",
    "                individual_word_tags[tag]=individual_word_tags.setdefault(tag,set((word)))\n",
    "        transition_count[pre_tag][tag]=transition_count[pre_tag].get(tag,0)+1\n",
    "        transition_count.setdefault(tag,{})\n",
    "        pre_tag=tag\n",
    "        if pre_tag not in transition_count:\n",
    "            transition_count[pre_tag]=transition_count.setdefault()\n",
    "        if word not in emission_count:\n",
    "            emission_count[word][tag]=emission_count.setdefault(word,{}).setdefault(tag,1)\n",
    "        else:\n",
    "            emission_count[word][tag]=emission_count[word].get(tag,0)+1\n",
    "\n",
    "for tag_i in tag_count.keys():\n",
    "    for tag_j in tag_count.keys():\n",
    "        transition_count[tag_i][tag_j]=transition_count[tag_i].get(tag_j,0)+1\n",
    "        tag_count[tag_j]+=1\n",
    "\n",
    "for tag_i in transition_count:\n",
    "    for tag_j in transition_count[tag_i]:\n",
    "        transition_count[tag_i][tag_j]/=tag_count[tag_i]\n",
    "\n",
    "for word in emission_count:\n",
    "    for tag in emission_count[word]:\n",
    "        emission_count[word][tag]/=tag_count[tag]\n",
    "\n",
    "most_probable_count= sorted(individual_word_tags, key=lambda k: len(individual_word_tags[k]), reverse=True)\n",
    "\n",
    "with open('hmmmodel.txt','w') as file:\n",
    "    file.write(json.dumps({\"tag_count\":tag_count,\"transition_count\":transition_count,\"emission_count\":emission_count,\"most_probable_count\":most_probable_count}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
